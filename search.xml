<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>ML Homework 1 Perceptron</title>
    <url>/2021/04/01/ML-Homework-1-Perceptron/</url>
    <content><![CDATA[<h1 id="ML-Homework-1-Perceptron"><a href="#ML-Homework-1-Perceptron" class="headerlink" title="ML Homework 1 Perceptron"></a>ML Homework 1 Perceptron</h1><h3 id="題目"><a href="#題目" class="headerlink" title="題目"></a>題目</h3><p><img src="https://i.imgur.com/1tyoThM.png" alt="題目"></p>
<ol>
<li><p>使用具有特定參數m和b的線性方程式 y = mx + b 來生成30個2D數據樣本。將右側的15個數據樣本標記為正，左側的15個數據樣本標記為負。並且沒有樣本在線上。</p>
</li>
<li><p>用您自己的初始w實現Perceptron Learning Algorithm。 討論PLA是否停止或它暫停了多少次迭代。生成三次數據樣本併計算平均值PLA暫停時的迭代次數。</p>
</li>
<li><p>在問題1中，生成1000個正樣本和1000個負樣本。 利用Pocket Algorithm，並將執行時間與同一數據集上的PLA進行比較。</p>
</li>
</ol>
<span id="more"></span>
<h3 id="Execution-description"><a href="#Execution-description" class="headerlink" title="Execution description"></a>Execution description</h3><h4 id="作業環境"><a href="#作業環境" class="headerlink" title="作業環境"></a>作業環境</h4><ul>
<li><p>作業系統: Windows 10</p>
</li>
<li><p>Requirments</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python&#x3D;&#x3D;3.6.5</span><br><span class="line">numpy&#x3D;&#x3D;1.14.3</span><br><span class="line">matplotlib&#x3D;&#x3D;2.2.2</span><br></pre></td></tr></table></figure>
<h4 id="執行方法"><a href="#執行方法" class="headerlink" title="執行方法"></a>執行方法</h4></li>
<li>在作業資料夾中打開命令提示字元</li>
<li>輸入以下指令即可執行  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python hw1.py</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="Experimental-results"><a href="#Experimental-results" class="headerlink" title="Experimental results"></a>Experimental results</h3><ol>
<li>畫出線性方程 y = mx + b (m=1, b=2)，以及30個標記點 (<span style='color:blue'>藍色</span>為正，<span style='color:red'>紅色</span>為負)<br> <img src="https://i.imgur.com/K70DEc3.jpg" alt=""></li>
</ol>
<ol>
<li><p>自訂初始 w([1,1])，實作PLA，並重複三次計算每次執行PLA的迭代次數以及三次平均次數</p>
<ul>
<li><p>第一次: 213次<br>  <img src="https://i.imgur.com/MxjCdRZ.jpg" alt=""></p>
<blockquote>
<p>藍線為 y = mx + b (m=1, b=2)</p>
<p>紅線為PLA最終答案</p>
</blockquote>
</li>
<li><p>第二次: 107次<br>  <img src="https://i.imgur.com/DElo6Pk.jpg" alt=""></p>
<blockquote>
<p>藍線為 y = mx + b (m=1, b=2)</p>
<p>紅線為PLA最終答案</p>
</blockquote>
</li>
<li><p>第三次: 70次<br>  <img src="https://i.imgur.com/GIHqPiW.jpg" alt=""></p>
<blockquote>
<p>藍線為 y = mx + b (m=1, b=2)</p>
<p>紅線為PLA最終答案</p>
</blockquote>
</li>
<li><p>迭代平均次數: 130次</p>
<p>  <img src="https://i.imgur.com/kMMgNSs.png" alt=""></p>
</li>
</ul>
</li>
</ol>
<ol>
<li><p>生成1000個正樣本和1000個負樣本。 自訂初始 w([1,1])，實作Pocket Algorithm，並將執行時間與同一數據集上的PLA進行比較。</p>
<ul>
<li><p>結果圖片<br>  <img src="https://i.imgur.com/bfDv0sL.jpg" alt=""></p>
<p>  因為看不清楚有三條線所以我們把線的部分放大<br>  <img src="https://i.imgur.com/EBnSQso.png" alt=""></p>
<blockquote>
<p>藍線為 y = mx + b (m=1, b=2)</p>
<p>紅線為PLA最終答案</p>
<p>灰線為Pocket Algorithm答案</p>
</blockquote>
</li>
<li><p>執行時間</p>
<p>  <img src="https://i.imgur.com/9BnbjJi.png" alt=""></p>
<ul>
<li>PLA: 0.0625 seconds</li>
<li>Pocket Algorithm: 1.3750 seconds</li>
</ul>
</li>
<li><p><a href="https://github.com/Cheryl115/ML-hw1">程式碼</a>在這裡</p>
</li>
</ul>
</li>
</ol>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><h4 id="What-is-Perceptron-Learning-Algorithm"><a href="#What-is-Perceptron-Learning-Algorithm" class="headerlink" title="What is Perceptron Learning Algorithm?"></a>What is Perceptron Learning Algorithm?</h4><ul>
<li><p>用在可以完全二分的問題中，經由不斷的修正錯誤，求得一個<span style='color:#FF8888'>完美</span>的分類器。</p>
</li>
<li><p>如何判斷錯誤?</p>
<ul>
<li>將${w_t}$ 與 ${x_{n(t)}}$做內積，看是不是我們要的正負號。<script type="math/tex; mode=display">sign({w\_t^T}{x\_{n(t)}}) \neq {y\_{n(t)}}</script></li>
</ul>
</li>
<li><p>如何修正錯誤?</p>
<ul>
<li><p>根據正負耗去調整w，如果是正的，那就把w轉的靠近x一點，如果是負的，就把w轉的遠離x一點。</p>
<script type="math/tex; mode=display">{w\_{t+1}}\space\leftarrow\space{w\_t}+{y\_{n(t)}}{x\_{n(t)}}</script></li>
</ul>
</li>
<li><p>不斷重複上述兩步驟直到沒有錯誤</p>
</li>
</ul>
<h4 id="What-is-Pocket-Algorithm"><a href="#What-is-Pocket-Algorithm" class="headerlink" title="What is Pocket Algorithm?"></a>What is Pocket Algorithm?</h4><ul>
<li>為PLA的變形，目的是找出一個<span style='color:#FF8888'>相對好</span>的分類器</li>
<li>在每次進行修正的時候都把新的${w_t}$跟舊的${w}$做比較，如果${w_t}$的誤差值較小，則更新目前口袋中的${w}$值，經過不斷的迭代，${w}$中的值必定可以找到<span style='color:#FF8888'>當下最好</span>的分類器</li>
</ul>
<h3 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h3><ul>
<li><p>為什麼PLA有時候會無法停止？</p>
<ul>
<li>因為資料樣本不是線性可分</li>
</ul>
</li>
<li><p>為什麼使用Pocket Algorithm的時候，會出現沒被準確分類的樣本？</p>
<ul>
<li>因為Pocket Algorithm的目的是找出相對好的w，為了避免遇到不是線性可分的資料，有限制迭代的上限次數，所以有時候會出現沒被準確分類的樣本。</li>
</ul>
</li>
<li><p>為什麼Pocket Algorithm常常比PLA慢?</p>
<ul>
<li>因為Pocket Algorithm每次調整w時，都會重新計算一次w的正確率，所以通常會比較久</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
</search>
